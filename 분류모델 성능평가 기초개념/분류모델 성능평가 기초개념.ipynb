{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 190425 작업중\n",
    "\n",
    "#### # 학습 시 참고 URL : https://datascienceschool.net\n",
    "\n",
    "#### 1. 분류문제 성능평가 개요\n",
    "\n",
    "우리가 회귀분석을 할때는 성능평가 기준이 비교적 간단했다. 항상 그런건 아니지만 대부분의 경우에는 잔차제곱합 RSS를 줄이면 우리가 원하는 좋은 모델이 되는 경우가 많았다.\n",
    "\n",
    "그러나 분류문제에 있어서는 성능을 평가하는 것이 회귀분석과 비교했을때 복잡하다.\n",
    "\n",
    "Scikit-Learn 에서 지원하는 분류 성능평가 sklearn.metrics 서브 패키지의 메서드만 해도 아래와 같이 7개가 있다.\n",
    "\n",
    "1) confusion_matrix()\n",
    "\n",
    "2) classfication_report()\n",
    "\n",
    "3) accuracy_score(y_true, y_pred)\n",
    "\n",
    "4) precision_score(y_true, y_pred)\n",
    "\n",
    "5) recall_score(y_true, y_pred)\n",
    "\n",
    "6) fbeta_score(y_true, y_pred, beta)\n",
    "\n",
    "7) f1_score(y_true, y_pred)\n",
    "\n",
    "#### 2. confusion matrix (분류결과표)\n",
    "\n",
    "먼저 confusion matrix에 대해 알아보자. 어떤 classification을 했을때 가장 기본적으로 결과를 나타내는 리포트가 Confusion Matrix 또는 Confusion Table 이라는게 있다.\n",
    "\n",
    "Confusion Matrix는 타겟의 원래 클래스와 모형이 예측한 클래스가 일치하는지는 갯수로 센 결과이다. 원래 클래스는 행으로 예측한 클래스는 열로 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"1.jpg\" width=\"1000\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분류모형에 대한 성능이 위와같이 정량화되어 테이블 형태로 나오게 된다.\n",
    "\n",
    "좋은모델은 정답을 맞추는 대각선 부분의 숫자가 많고, 비대각선 부분이 적어야 한다.\n",
    "\n",
    "#### 3. Binary Confusion Matrix (이진분류 결과표)\n",
    "\n",
    "- 통상적으로 양성반응은 Positive(ex) 사기거래,환자 등), 음성은 Negative(ex) 정상거래,정상인 등)\n",
    "\n",
    "\n",
    "- 결과표는 prediction한 결과로 작성하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"2.jpg\" width=\"1000\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 평가점수\n",
    "\n",
    "위와 같이 3x3가 되었든 2x2가 되었든 confusion matrix로 결과를 보게되면 정량적으로 모델의 성능을 확인할 수 있다. 이것만으로 어떤 스코어라고 말할 수 없다. 숫자가 하나가 아니라 9개나 4개이기 때문이다. 그래서 우리가 무언가 평가를 하려면 하나의 숫자 스칼라값으로 압축을 시켜야한다. 예를들어서 회귀분석할때는 RSS로 압축하듯이 그렇게 해줘야 한다. 분류문제도 마찬가지로 1개의 숫자로 나타낼 수 있어야 한다.\n",
    "\n",
    "그런 평가방법들이 아래의 그림과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"3.jpg\" width=\"1000\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- accuracy는 전체문제 중에 모델이 맞춘것만 따진다는 것이다. 가장 상식적인 방법이다. 내가 푼 모든문제 다시말해 2x2 confusion matrix라면 4개의 cell의 모든 값들 중 TP + TN 의 비율을 말한다. 현실적으로 우리가 만드는 모델들은 전부 이거를 기준으로 최적모델을 찾는다.\n",
    "\n",
    "\n",
    "- 그러면 accuracy만 쓰면 되지 다른 지표들은 왜있는거냐. 분류문제에서는 특히나 이진분류표에서 각각의 셀은 이런것들이 현실적으로는 모두가 똑같은 중요도를 갖고 있지 않다. 푸는문제에 따라 각각의 셀의 중요도가 달라지게 된다. 가장 대표적인 예가 진단과 QA문제이다. 실제로 정상인인데 암환자라고 오진하는 것도 문제지만 실제 환자인데 정상인이라고 판별하는 것은 그 사람에게는 정말 치명적인 문제이기 때문이다. QA문제도 마찬가지로 이 타이어가 실제로는 문제가 있는데 정상제품이라고 판별을 하는 순간 이 제품을 쓰는 소비자의 안전에 치명타가 될 수 있는 문제이다. 이런문제는 recall이 무조건 100프로를 지향해야한다.\n",
    "\n",
    "\n",
    "- 그래서 단순히 accuracy만 볼 문제가 아니기 때문에 여러가지면에서 스코어를 측정할 수 있어야 한다는 아이디어에서 위와 같이 각각의 케이스에 따른 평가방법이 있는 것이다.\n",
    "\n",
    "\n",
    "- 반대로 fallout은 억울한 케이스의 비율이기 때문에 recall과 대조적으로 낮은 수치를 지향해야한다.\n",
    "\n",
    "\n",
    "- 위에서 설명한 각종 평가 점수들은 서로 밀접한 관계를 맺고 있다. 예를 들어 recall과fall-out은 양의 상관관계가 있다. 그리고 precision와 recall은 대략적으로 음의 상관 관계가 있다.\n",
    "\n",
    "recall을 높이기 위해서는 양성으로 판단하는 기준(threshold)을 낮추어 약간의 증거만 있어도 양성으로 판단하도록 하면 된다. 그러나 이렇게 되면 음성임에도 양성으로 판단되는 표본 데이터가 같이 증가하게 되어 fall-out이 동시에 증가한다. \n",
    "\n",
    "반대로 fall-out을 낮추기 위해 양성을 판단하는 기준을 엄격하게 두게 되면 증거부족으로 음 판단을 받는 표본 데이터의 수가 같이 증가하므로 recall이 떨어진다.\n",
    "\n",
    "정밀도의 경우에는 recall과 fall-out처럼 정확한 상관관계는 아니지만 대략적으로 음의 상관 관계를 가진다. 즉 정밀도를 높이기 위해 판단 기준을 엄격하게 할수록 재현율이나 위양성율이 감소하는 경향을 띤다.\n",
    "\n",
    "\n",
    "- F score에서 어느한쪽에 가중치를 더 두고 싶다하면 배타를 조정하면 된다. precision에 더 가중치를 두고 싶다고하면 배타를 1보다 크게해주면 된다. 그러면 precision에 조금 더 가중치를 주게 된다. 통상적으로 배타를 얼마를 두냐라는 기준이 없어서 1로 두는경우가 많다. 배타를 1로 두는 경우를 F1 score라고 한다.\n",
    "\n",
    "\n",
    "- 우리가 분류모델을 만들고 classification report를 출력하게 되면 아래와 같은 표가 나오게 된다.(classification report 예시) \n",
    "\n",
    "여기서 참고로 support는 실제로 정답이 class 0인 데이터의 갯수 5개, 실제로 정답이 class 1인 데이터의 갯수 2개를 말한다.\n",
    "\n",
    "우리가 이 report를 보고 보통은 밑에 avg 부분을 보는경우가 많다. 그 중에서도 f1-score의 avg를 기본적인 퍼포먼스로 보는 경우가 많다. 그러나 이것만 딱 보면은 안된다. 위에도 언급했듯이 문제가 어떤 문제냐에 따라 recall rate가 중요한 경우가 있기 때문이다.\n",
    "\n",
    "가끔은 이런경우가 나오기도 한다. 전체 평균은 60 ~ 70인데 리콜벨류만 확떨어지는 경우가 있다. 어떤 특정한 클래스 얘들을 전혀 못잡는 현상인 것이다. 그렇게되면 문제가 뭐냐에 따라 달라지기는 하지만 그 문제가 리콜이 중요한 문제라고 하면 그러면 이 모델이 무언가 잘못된 것이라고 판단하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"4.jpg\" width=\"1000\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
