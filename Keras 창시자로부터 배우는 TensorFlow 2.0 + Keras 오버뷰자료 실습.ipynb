{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras 창시자로부터 배우는 TensorFlow 2.0 + Keras 오버뷰자료 실습.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt-ixwGue_WL",
        "colab_type": "text"
      },
      "source": [
        ".\n",
        "\n",
        "Deep_Learning_TIL_(20200228)\n",
        "\n",
        "- 학습 시 참고자료(출처) \n",
        "\n",
        "자료 : Keras 창시자로부터 배우는 TensorFlow 2.0 + Keras 특강\n",
        "\n",
        "URL : https://colab.research.google.com/drive/1p4RhSj1FEuscyZP81ocn8IeGD_2r46fS?fbclid=IwAR0qED1D3sAQk4oEVC0IolOopC9ur3LlnUsHFLl-YyFHuPUPtUxk4YUBVa0\n",
        "\n",
        "- 실습환경 : Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTuxi-1k1F2C",
        "colab_type": "code",
        "outputId": "ac879b4d-05ec-4947-d0a7-b4bf86ebf20a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 52kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.27.1)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 58.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.9.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 70.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.17.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.1.8)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.11.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (45.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.7.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.21.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.2.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.8.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W15eefa2Q5hA",
        "colab_type": "code",
        "outputId": "95db6112-9685-4bb6-adee-8a1d018df80a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoDjozMFREDU",
        "colab_type": "text"
      },
      "source": [
        "# TensorFlow 2.0 + Keras, 딥러닝 연구자들을 위한 오버뷰\n",
        "\n",
        "*@fchollet, October 2019 (번역 @chansung)*\n",
        "- 원본은 [TensorFlow 2.0 + Keras Overview for Deep Learning Researchers](https://colab.research.google.com/drive/1UCJt8EYjlzCs1H1d1X0iDGYJsHKwu-NO?fbclid=IwAR269Y-3J1DuZL01L6GBCC4dg6RSAmJXHnRfztL454dZ5SqKLRxCAZcxzgY)입니다.\n",
        "---\n",
        "\n",
        "**이 문서는 입문, 특강, 그리고 TensorFlow 2.0의 API를 빠르게 참조하는 목적을 위해 제공됩니다.**\n",
        "\n",
        "---\n",
        "\n",
        "TensorFlow와 Keras는 모두 약 4년전쯤 릴리즈 되었습니다 (Keras는 2015년 3월, TensorFlow는 2015년 11월). 이는 딥러닝 세계의 관점에서 볼 때, 꽤 오랜시간이라고 볼 수 있습니다!\n",
        "\n",
        "과거에 TensorFlow 1.x + Keras는 여러가지 알려진 문제점을 가지고 있었습니다:\n",
        "- TensorFlow를 사용한다는것은 정적인 계산 그래프를 조작함을 의미하는것으로, Imperative 코딩 스타일을 사용하는 프로그래머로 하여금 어렵고, 불편한 느낌을 받게 했었습니다.\n",
        "- TensorFlow API가 매우 강력하면서도 유연하지만, 빠른 코드의 작성의 가능성이 결여되어 있었으며 종종 사용법은 어렵고 혼란스러웠습니다.\n",
        "- Keras는 매우 생산적이고 사용이 쉽지만, 연구에 사용된 사례에서 종종 유연성이 결여되었었습니다.\n",
        "\n",
        "---\n",
        "### TensorFlow 2.0은 TensorFlow와 Keras를 대대적으로 새로이 디자인한 것으로, 지난 4년간의 사용자 피드백과 기술의 진보가 모두 고려되었습니다. 위에서 언급된 문제점들을 대규모로 수정합니다.\n",
        "\n",
        "### 미래에서온 차세대 머신러닝 플랫폼입니다\n",
        "\n",
        "---\n",
        "\n",
        "TensorFlow 2.0은 아래와 같은 주요 아이디어에 기반하고 있습니다:\n",
        "\n",
        "- 사용자들이 계산을 eagerly하게 수행할 수 있게 해줍니다. 이는 Numpy를 사용하는법과 유사합니다. 이는 TensorFlow 2.0을 이용한 프로그래밍이 직관적이며 동시에 파이토닉할 수 있게끔 해 줍니다.\n",
        "- 컴파일된 그래프의 엄청난 이점을 그대로 보존하는데, 이는 성능, 분산, 그리고 배포를 위함입니다. 이 내용은 TensorFlow를 빠르고, 분산 구조에서의 확장 가능하며, 상용화에 준비될 수 있도록 해 줍니다.\n",
        "- Keras를 딥러닝의 고수준 API로 채택하여, TensorFlow를 이해하기 쉬우면서도 높은 생산성을 가질 수 있게 만들어 줍니다.\n",
        "- 매우 고수준(더 쉬운 사용성, 약간 부족한 유연성) 에서부터 매우 저수준(더 깊은 전문성, 매우 뛰어난 유연성)의 다양한 범위의 작업으로까지 Keras를 확장합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U71NYDeFkUhq",
        "colab_type": "text"
      },
      "source": [
        "# 파트 1: TensorFlow의 기본"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2e8-qrcl2kH",
        "colab_type": "text"
      },
      "source": [
        "## Tensors (텐서)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX6JvH4h0zyY",
        "colab_type": "text"
      },
      "source": [
        "다음은 [상수형](https://www.tensorflow.org/api_docs/python/tf/constant) 텐서 입니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGB6GDsfRFJs",
        "colab_type": "code",
        "outputId": "2e6b69ad-4956-421e-d428-9cd9bf7d7246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "x = tf.constant([[5, 2], [1, 3]])\n",
        "print(x)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[5 2]\n",
            " [1 3]], shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX2SB_2O1jx7",
        "colab_type": "text"
      },
      "source": [
        "해당 텐서의 값을 Numpy 배열형태로 가져오고 싶다면 `.numpy()`를 호출하면 됩니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwGyHOoq1oWn",
        "colab_type": "code",
        "outputId": "7331b25d-cffb-4198-95b0-0823f718c014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "x.numpy()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5, 2],\n",
              "       [1, 3]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNkno66r1xvg",
        "colab_type": "text"
      },
      "source": [
        "Numpy 배열과 *꽤나* 유사한 점으로 `dtype`과 `shape`이라는 속성을 가집니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSxtblSP13v2",
        "colab_type": "code",
        "outputId": "81cd8d0d-2882-4974-d80e-bea6b04422a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print('dtype:', x.dtype)\n",
        "print('shape:', x.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dtype: <dtype: 'int32'>\n",
            "shape: (2, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oogzv3--2EF2",
        "colab_type": "text"
      },
      "source": [
        "상수형 텐서를 생성하는 보편적인 방법은 `tf.ones`과 `tf.zeros`를 사용하는 것입니다(이는 Numpy의 `np.ones` 및 `np.zeros`와 유사합니다):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qDlfa8r2Lia",
        "colab_type": "code",
        "outputId": "d85ded4a-d34a-4dc4-d6fb-bc92faa823cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "print(tf.ones(shape=(2, 1)))\n",
        "print(tf.zeros(shape=(2, 1)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1.]\n",
            " [1.]], shape=(2, 1), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.]\n",
            " [0.]], shape=(2, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzGYEkdcmYbe",
        "colab_type": "text"
      },
      "source": [
        "## 랜덤한 상수형 텐서"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk94gREJ2r-e",
        "colab_type": "text"
      },
      "source": [
        "다음은 랜덤한 [정규분포](https://www.tensorflow.org/api_docs/python/tf/random/normal)로부터 상수를 생성합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqRrO-Puma7-",
        "colab_type": "code",
        "outputId": "c832bc4b-bbc8-4daf-dab0-63b0ea31e0dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "tf.random.normal(shape=(2, 2), mean=0., stddev=1.)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=12, shape=(2, 2), dtype=float32, numpy=\n",
              "array([[-1.0932361,  2.228664 ],\n",
              "       [-0.8287051, -0.9424461]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL0EMPT93SEU",
        "colab_type": "text"
      },
      "source": [
        "*그리고* 다음은 랜덤한 [균등분포](https://www.tensorflow.org/api_docs/python/tf/random/uniform)로부터 값이 채워지는 정수형 텐서를 보여줍니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9syARhtj2wbx",
        "colab_type": "code",
        "outputId": "005b14af-3c8a-4543-ea09-3b0c50319b21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "tf.random.uniform(shape=(2, 2), minval=0, maxval=10, dtype='int32')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=16, shape=(2, 2), dtype=int32, numpy=\n",
              "array([[0, 3],\n",
              "       [5, 1]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I95066exmbDU",
        "colab_type": "text"
      },
      "source": [
        "## Variables (변수)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMflzgPM3Mim",
        "colab_type": "text"
      },
      "source": [
        "[Variables](https://www.tensorflow.org/guide/variable)는 변할 수 있는 상태(뉴럴넷의 가중치와 같은)를 저장하는데 사용되는 특별한 텐서 입니다. 초기값을 사용해서 Variable을 생성할 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FvENXmBmcyT",
        "colab_type": "code",
        "outputId": "bbc38e1b-56ab-4f3b-82bb-748ee18ff3ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "initial_value = tf.random.normal(shape=(2, 2))\n",
        "a = tf.Variable(initial_value)\n",
        "print(a)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[-1.4263921 ,  0.49103293],\n",
            "       [-0.36253545,  1.8493237 ]], dtype=float32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRFwVySi3biu",
        "colab_type": "text"
      },
      "source": [
        "`.assign(value)`, `.assign_add(increment)`, 또는 `.assign_sub(decrement)`와 같은 메소드를 사용해서 Variable의 값을 갱신합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOCsCNvc3mNR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ae0c9850-c4d2-4969-fd1e-b812b79dbe6b"
      },
      "source": [
        "new_value = tf.random.normal(shape=(2, 2))\n",
        "a.assign(new_value)\n",
        "for i in range(2):\n",
        "  for j in range(2):\n",
        "    assert a[i, j] == new_value[i, j]\n",
        "\n",
        "print(a)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ 1.5460566 ,  1.1849345 ],\n",
            "       [ 0.24738911, -0.30803028]], dtype=float32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrSjwl_056j8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "96d0e77d-c9f4-4c71-978f-7c0572446499"
      },
      "source": [
        "added_value = tf.random.normal(shape=(2, 2))\n",
        "a.assign_add(added_value)\n",
        "for i in range(2):\n",
        "  for j in range(2):\n",
        "    assert a[i, j] == new_value[i, j] + added_value[i, j]\n",
        "\n",
        "print(a)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ 0.83296186,  0.58070505],\n",
            "       [ 1.7173103 , -0.678332  ]], dtype=float32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAIqYQmOl_wR",
        "colab_type": "text"
      },
      "source": [
        "## TensorFlow에서 수학을 하는것"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bmtTepn6SvG",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow는 Numpy를 사용하는것과 정확히 똑같은 방법으로 사용할 수 있습니다. 이 둘의 주요 다른점은 작성한 TensorFlow의 코드는 GPU와 TPU 상에서 실행될 수 있다는 점입니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCZGHQ_XmHuZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "20b603c1-3cc2-449d-a021-b5ac6ccc4d35"
      },
      "source": [
        "a = tf.random.normal(shape=(2, 2))\n",
        "b = tf.random.normal(shape=(2, 2))\n",
        "\n",
        "c = a + b\n",
        "d = tf.square(c)\n",
        "e = tf.exp(d)\n",
        "\n",
        "print(a,'\\n',b,'\\n',c,'\\n',d,'\\n',e)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-1.7188389  -0.715927  ]\n",
            " [-0.14043556  0.7175207 ]], shape=(2, 2), dtype=float32) \n",
            " tf.Tensor(\n",
            "[[-0.36652637  0.55603373]\n",
            " [ 0.89047074  0.614373  ]], shape=(2, 2), dtype=float32) \n",
            " tf.Tensor(\n",
            "[[-2.0853653  -0.15989327]\n",
            " [ 0.75003517  1.3318937 ]], shape=(2, 2), dtype=float32) \n",
            " tf.Tensor(\n",
            "[[4.348748   0.02556586]\n",
            " [0.56255275 1.7739408 ]], shape=(2, 2), dtype=float32) \n",
            " tf.Tensor(\n",
            "[[77.38154    1.0258955]\n",
            " [ 1.7551472  5.894035 ]], shape=(2, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Feq3qWoBVQW",
        "colab_type": "text"
      },
      "source": [
        "## `GradientTape`을 사용해서 경사도를 계산하는것"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdsmOcrJBWXe",
        "colab_type": "text"
      },
      "source": [
        "한 가지 더 Numpy와의 큰 차이점이 있습니다: 모든 미분가능한 표현에 대해서, 자동으로 경사도를 구하는 것이 가능합니다.\n",
        "\n",
        "단순히 [`GradientTape`](https://www.tensorflow.org/api_docs/python/tf/GradientTape)를 열게되면, 그때부턴 `tape.watch()`를 통해 텐서를 확인하고, 이 텐서를 입력으로써 사용하는 미분가능한 표현을 구성하는것이 가능합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkEAY45IBjPv",
        "colab_type": "code",
        "outputId": "5ceb62cb-e812-4849-c819-c78e6b7adeac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "a = tf.random.normal(shape=(2, 2))\n",
        "b = tf.random.normal(shape=(2, 2))\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(a)  # `a`에 적용되는 연산의 히스토리에 대한 기록을 시작\n",
        "  c = tf.sqrt(tf.square(a) + tf.square(b))  # `a`를 사용하여 몇 가지 수학을 수행\n",
        "  # `a`에 대한 `c`의 경사도는 무엇인가?\n",
        "  dc_da = tape.gradient(c, a)\n",
        "  print(dc_da)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.94430184  0.04223739]\n",
            " [-0.860221    0.6537137 ]], shape=(2, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8UpqFx_DDbV",
        "colab_type": "text"
      },
      "source": [
        "디폴트로는 Variable들은 자동으로 watch가 적용되어 있기 때문에, 수동으로 `watch`를 해 줄 필요는 없습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtH3FuvDDOAY",
        "colab_type": "code",
        "outputId": "8287c5ad-e3e9-4594-8228-a43060156329",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "a = tf.Variable(a)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  c = tf.sqrt(tf.square(a) + tf.square(b))\n",
        "  dc_da = tape.gradient(c, a)\n",
        "  print(dc_da)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.94430184  0.04223739]\n",
            " [-0.860221    0.6537137 ]], shape=(2, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFlBGjuEDbt-",
        "colab_type": "text"
      },
      "source": [
        "GradientTape을 중첩시켜서 고차원의 미분을 계산할 수도 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjPcY0OIDhEA",
        "colab_type": "code",
        "outputId": "7c0b9820-8826-42ac-b2a4-675da6947e39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "with tf.GradientTape() as outer_tape:\n",
        "  with tf.GradientTape() as tape:\n",
        "    c = tf.sqrt(tf.square(a) + tf.square(b))\n",
        "    dc_da = tape.gradient(c, a)\n",
        "  d2c_da2 = outer_tape.gradient(dc_da, a)\n",
        "  print(d2c_da2)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.14804387 0.35640335]\n",
            " [0.40593112 2.9766662 ]], shape=(2, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KC5RgwGeBP-9",
        "colab_type": "text"
      },
      "source": [
        "## end-to-end 예제: 선형 회귀"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Owbx4mlEErNN",
        "colab_type": "text"
      },
      "source": [
        "지금까지 TensorFlow는 Numpy와 비슷한 라이브러리인데, 추가적으로 GPU 또는 TPU를 통해 가속될 수 있고, 자동으로 미분이 계산된다는 내용을 배웠습니다. 그러면 이제는 end-to-end 예제를 알아볼 시간입니다: 머신러닝의 피즈버즈인, 선형 회귀를 구현해 봅시다. \n",
        "\n",
        "이를 보여주기 위해서, `Layer` 또는 `MeanSquaredError`와 같은 Keras의 고수준 컴포넌트를 사용하지 않을 것입니다. 단지 기본적인 연산자만을 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhitqoj2FH8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = 2\n",
        "output_dim = 1\n",
        "learning_rate = 0.01\n",
        "\n",
        "# 가중치 행렬입니다\n",
        "w = tf.Variable(tf.random.uniform(shape=(input_dim, output_dim)))\n",
        "# 편향 벡터입니다\n",
        "b = tf.Variable(tf.zeros(shape=(output_dim,)))\n",
        "\n",
        "def compute_predictions(features):\n",
        "  return tf.matmul(features, w) + b\n",
        "\n",
        "def compute_loss(labels, predictions):\n",
        "  return tf.reduce_mean(tf.square(labels - predictions))\n",
        "\n",
        "def train_on_batch(x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = compute_predictions(x)\n",
        "    loss = compute_loss(y, predictions)\n",
        "    dloss_dw, dloss_db = tape.gradient(loss, [w, b])\n",
        "  w.assign_sub(learning_rate * dloss_dw)\n",
        "  b.assign_sub(learning_rate * dloss_db)\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qC1fp3BYJeXo",
        "colab_type": "text"
      },
      "source": [
        "작성한 모델을 검증하기 위한, 인공적인 데이터를 생성해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ocAkrliMVAQ",
        "colab_type": "code",
        "outputId": "ea9aac02-f962-4fcf-bd6d-50b3e8997e36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# 데이터셋을 준비합니다\n",
        "num_samples = 10000\n",
        "negative_samples = np.random.multivariate_normal(\n",
        "    mean=[0, 3], cov=[[1, 0.5],[0.5, 1]], size=num_samples)\n",
        "positive_samples = np.random.multivariate_normal(\n",
        "    mean=[3, 0], cov=[[1, 0.5],[0.5, 1]], size=num_samples)\n",
        "features = np.vstack((negative_samples, positive_samples)).astype(np.float32)\n",
        "labels = np.vstack((np.zeros((num_samples, 1), dtype='float32'),\n",
        "                    np.ones((num_samples, 1), dtype='float32')))\n",
        "\n",
        "plt.scatter(features[:, 0], features[:, 1], c=labels[:, 0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7ff0b5880550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8/9v7VHwHJsisAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCdZTpjlJlGo",
        "colab_type": "text"
      },
      "source": [
        "그러면, 데이터의 배치크기 단위로 돌면서, `train_on_batch` 함수를 반복적으로 호출하여 선형 회귀 모델을 학습시켜 봅시다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsHszjjaJDQZ",
        "colab_type": "code",
        "outputId": "e92dcd64-6a38-44c8-e5d1-d25cd9ca2c49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "# 데이터를 무작위로 섞습니다\n",
        "random.Random(1337).shuffle(features)\n",
        "random.Random(1337).shuffle(labels)\n",
        "\n",
        "# 손쉽게 배치화된 반복을 위해, tf.data.Dataset 객체를 생성합니다\n",
        "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(256)\n",
        "\n",
        "for epoch in range(10):\n",
        "  for step, (x, y) in enumerate(dataset):\n",
        "    loss = train_on_batch(x, y)\n",
        "  print('Epoch %d: 마지막 배치의 손실값 = %.4f' % (epoch, float(loss)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 마지막 배치의 손실값 = 0.0537\n",
            "Epoch 1: 마지막 배치의 손실값 = 0.0898\n",
            "Epoch 2: 마지막 배치의 손실값 = 0.0370\n",
            "Epoch 3: 마지막 배치의 손실값 = 0.0332\n",
            "Epoch 4: 마지막 배치의 손실값 = 0.0399\n",
            "Epoch 5: 마지막 배치의 손실값 = 0.0331\n",
            "Epoch 6: 마지막 배치의 손실값 = 0.0174\n",
            "Epoch 7: 마지막 배치의 손실값 = 0.0242\n",
            "Epoch 8: 마지막 배치의 손실값 = 0.0270\n",
            "Epoch 9: 마지막 배치의 손실값 = 0.0301\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIDDhTcyJwSM",
        "colab_type": "text"
      },
      "source": [
        "아래는 우리가 만든 모델이 얼마나 잘 동작하는지를 보여줍니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBPYQpskJxxT",
        "colab_type": "code",
        "outputId": "1f6bc23b-5aef-4cd6-c70d-123c347728ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "predictions = compute_predictions(features)\n",
        "plt.scatter(features[:, 0], features[:, 1], c=predictions[:, 0] > 0.5)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7ff0b1b73080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBcqiop7mH7x",
        "colab_type": "text"
      },
      "source": [
        "## `tf.function`를 이용해서 속도를 빠르게 하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjZ8kuruNdj6",
        "colab_type": "text"
      },
      "source": [
        "현재의 코드는 얼마나 빨리 수행될까요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXoe7S5RmStB",
        "colab_type": "code",
        "outputId": "7e9b68b0-0e63-4c4d-92ea-06289c124f57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "for epoch in range(20):\n",
        "  for step, (x, y) in enumerate(dataset):\n",
        "    loss = train_on_batch(x, y)\n",
        "t_end = time.time() - t0\n",
        "print('epoch당 걸린 시간: %.3f 초' % (t_end / 20,))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch당 걸린 시간: 0.117 초\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHsvPqyRN_E3",
        "colab_type": "text"
      },
      "source": [
        "학습 함수를 정적 그래프로 컴파일 해 봅시다. 이를 위해서 해야할 것은 문자 그대로, `tf.function`이라는 데코레이터를 위에 넣어주는것 뿐입니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEYFkThcOGcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_on_batch(x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = compute_predictions(x)\n",
        "    loss = compute_loss(y, predictions)\n",
        "    dloss_dw, dloss_db = tape.gradient(loss, [w, b])\n",
        "  w.assign_sub(learning_rate * dloss_dw)\n",
        "  b.assign_sub(learning_rate * dloss_db)\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocOuskvoOKsx",
        "colab_type": "text"
      },
      "source": [
        "다시한번 시간을 측정해 봅시다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT2w6DVmONB5",
        "colab_type": "code",
        "outputId": "1c776ba1-4d98-40b0-bf43-37277bb00f65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "t0 = time.time()\n",
        "for epoch in range(20):\n",
        "  for step, (x, y) in enumerate(dataset):\n",
        "    loss = train_on_batch(x, y)\n",
        "t_end = time.time() - t0\n",
        "print('epoch당 걸린 시간: %.3f 초' % (t_end / 20,))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch당 걸린 시간: 0.078 초\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYPWZaSqOfEL",
        "colab_type": "text"
      },
      "source": [
        "걸린 시간이 약 40% 감소했습니다. 이 경우, 매우 간단한 모델을 사용했습니다; 일반적으로 모델이 크면 클 수록, 정적 그래프를 활용한 속도 개선은 더 많이 이뤄집니다.\n",
        "\n",
        "기억해야할 것이 있습니다: eager 실행모드는 디버깅과 코드 라인별 결과를 출력하는데 매우 유용하지만, 크기를 키워야할 시기가 오면, 정적 그래프가 연구자들에게 최고의 친구가 될 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3I3v_FqjFty",
        "colab_type": "text"
      },
      "source": [
        "# 파트 2: Keras API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjLI719fPfJi",
        "colab_type": "text"
      },
      "source": [
        "Keras는 딥러닝을 위한 파이썬 API 입니다. 모두가 사용할만한 내용을 가지고 있습니다:\n",
        "\n",
        "- 엔지니어의 경우, Keras는 계층, 평가지표(metrics), 학습 반복문과 같은 재사용 가능한 블록을 제공하여 일반적은 사용 사례를 지원합니다. 고수준의 사용자 경험을 제공하여 접근이 용이하고, 생산성이 좋습니다.\n",
        "\n",
        "- 연구자의 경우, 계층이나 학습 반목문과 같은 이미 제공되는 블록의 사용을 선호하지 않고, 스스로 만든 것을 대신 사용할 지도 모릅니다. 물론, Keras는 이를 가능하게 해 줍니다. 이 경우, Keras는 여러분이 작성하게될 블록에 대한 템플릿을 Layers 및 Metrics와 같은 표준적인 API와 함께 제공합니다. 이러한 구조는 다른 사람과 코드를 쉽게 공유하고, 상용의 작업 흐름에도 통합될 수 있게끔 해 줍니다.\n",
        "\n",
        "- 이 같은 내용은 라이브러리를 개발하는 분들에게도 적용되는 사실입니다. TensorFlow는 거대한 생태계죠. 수 많은 라이브러리가 존재합니다. 서로다른 라이브러리가 상호작용하고, 이들의 컴포넌트를 공유할 수 있게하기 위해선 API 표준을 따라야만 합니다. API 표준이 곧 Keras가 제공하는 핵심입니다.\n",
        "\n",
        "\n",
        "Keras는 결정적으로 고수준의 UX와 저수준의 유연성을 모두 함께 완만히 도입합니다. 이는 더이상 한편으론 사용성이 뛰어나지만 유연치는 못한 고수준 API를, 다른 한편으론 매우 유연하지만 전문가만이 사용가능한 저수준 API를 가져야만 하는 상황에서 벗어나게 해 줍니다. 그 대신, 매우 고수준에서부터 매우 저수준 까지의 다양한 작업 흐름의 범위를 가질 수 있게 됩니다. 이 작업흐름이란, 동일한 컨셉과 객체에 기반해서 만들어졌기 때문에 모든것이 상호 호환 가능한 것을 의미합니다.\n",
        "\n",
        "![Keras 작업 흐름의 범위](https://drive.google.com/uc?export=view&id=1bE0FiQY2XF5QzBLRHfe7-SdxvwGIO0GK)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9DSVjdHPkOw",
        "colab_type": "text"
      },
      "source": [
        "## `Layer` 기본 클래스\n",
        "\n",
        "가장 첫 번째로 알아야할 클래스는 [`Layer`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer) 입니다. Keras의 거의 모든것은 이 클래스로부터 파생됩니다.\n",
        "\n",
        "Layer는 상태(가중치, weights)와 몇 (`call` 메소드에 정의된)계산을 캡슐화 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io3dUQzaPnPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "class Linear(Layer):\n",
        "  \"\"\"y = w.x + b\"\"\"\n",
        "\n",
        "  def __init__(self, units=32, input_dim=32):\n",
        "      super(Linear, self).__init__()\n",
        "      w_init = tf.random_normal_initializer()\n",
        "      self.w = tf.Variable(\n",
        "          initial_value=w_init(shape=(input_dim, units), dtype='float32'),\n",
        "          trainable=True)\n",
        "      b_init = tf.zeros_initializer()\n",
        "      self.b = tf.Variable(\n",
        "          initial_value=b_init(shape=(units,), dtype='float32'),\n",
        "          trainable=True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "      return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "# 우리가 만든 Layer객체를 인스턴스화 합니다\n",
        "linear_layer = Linear(4, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo3etyK8BO4a",
        "colab_type": "text"
      },
      "source": [
        "Layer 인스턴스는 마치 함수처럼 동작합니다. 몇 데이터에 대해서 이를 호출해 봅시다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBUCLfHVBQLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = linear_layer(tf.ones((2, 2)))\n",
        "assert y.shape == (2, 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXqpznsxBaCC",
        "colab_type": "text"
      },
      "source": [
        "`Layer` 클래스는 속성으로써 부여된 weights를 통해서, 가중치들을 추적합니다 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_FaUtEYBeJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 가중치는 자동으로 `weights`라는 속성으로써 추적됩니다.\n",
        "assert linear_layer.weights == [linear_layer.w, linear_layer.b]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6PZ6QXUHdxA",
        "colab_type": "text"
      },
      "source": [
        "`add_weight`를 이용하여 간단히 가중치를 생성하는 방법이 있는것도 알아두세요. 이렇게 코드를 작성하는것 대신:\n",
        "\n",
        "```python\n",
        "w_init = tf.random_normal_initializer()\n",
        "self.w = tf.Variable(initial_value=w_init(shape=shape, dtype='float32'))\n",
        "```\n",
        "\n",
        "일반적으로 아래와 같이 작성합니다:\n",
        "\n",
        "```python\n",
        "self.w = self.add_weight(shape=shape, initializer='random_normal')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lphpMGIiHRUP",
        "colab_type": "text"
      },
      "source": [
        "`build`라는 별도의 메소드에서 가중치를 생성하는것이 좋은 관례입니다. 이 `build`는 Layer에 의해 첫 번째 입력의 Shape이 확인되는 순간 호출되는 lazy한 메소드 입니다. 이러한 패턴은 입력 차원(input_dim)을 생성자에 명시하지 않아도 되게 해 줍니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpPjScZKHXhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Linear(Layer):\n",
        "  \"\"\"y = w.x + b\"\"\"\n",
        "\n",
        "  def __init__(self, units=32):\n",
        "      super(Linear, self).__init__()\n",
        "      self.units = units\n",
        "\n",
        "  def build(self, input_shape):\n",
        "      self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                               initializer='random_normal',\n",
        "                               trainable=True)\n",
        "      self.b = self.add_weight(shape=(self.units,),\n",
        "                               initializer='random_normal',\n",
        "                               trainable=True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "      return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "\n",
        "# Lazy한 Layer의 인스턴스를 만듭니다.\n",
        "linear_layer = Linear(4)\n",
        "\n",
        "# 이렇게 하면, `build(input_shape)`이 호출되어 가중치를 생성하게 됩니다.\n",
        "y = linear_layer(tf.ones((2, 2)))\n",
        "assert len(linear_layer.weights) == 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86khdsF3Pnr0",
        "colab_type": "text"
      },
      "source": [
        "## 학습 가능한, 그리고 학습 불가능한 가중치"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32zvCEKLICr5",
        "colab_type": "text"
      },
      "source": [
        "Layer에 의해 생성된 가중치는 학습이 가능할 수도, 학습이 불가능할 수도 있습니다. 이 두 경우는 각각 \n",
        "`trainable_weights` 및 `non_trainable_weights`로써 노출되어 외부에서 접근 가능합니다. 다음은 학습 불가능한 가중치를 가지는 Layer를 보여줍니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ8s28NnX20u",
        "colab_type": "code",
        "outputId": "bb643393-2cf0-4eb8-e046-f0c4e9da55a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "class ComputeSum(Layer):\n",
        "  \"\"\"입력의 합산 결과를 반환하는 Layer\"\"\"\n",
        "\n",
        "  def __init__(self, input_dim):\n",
        "      super(ComputeSum, self).__init__()\n",
        "      # 학습 불가능한 가중치를 생성합니다.\n",
        "      self.total = tf.Variable(initial_value=tf.zeros((input_dim,)),\n",
        "                               trainable=False)\n",
        "\n",
        "  def call(self, inputs):\n",
        "      self.total.assign_add(tf.reduce_sum(inputs, axis=0))\n",
        "      return self.total  \n",
        "\n",
        "my_sum = ComputeSum(2)\n",
        "x = tf.ones((2, 2))\n",
        "\n",
        "y = my_sum(x)\n",
        "print(y.numpy())  # [2. 2.]\n",
        "\n",
        "y = my_sum(x)\n",
        "print(y.numpy())  # [4. 4.]\n",
        "\n",
        "assert my_sum.weights == [my_sum.total]\n",
        "assert my_sum.non_trainable_weights == [my_sum.total]\n",
        "assert my_sum.trainable_weights == []"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 2.]\n",
            "[4. 4.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oBkX6ZfYO8j",
        "colab_type": "text"
      },
      "source": [
        "## 재귀적으로 Layer를 조합하는것"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeLDL9MJI2dK",
        "colab_type": "text"
      },
      "source": [
        "Layer들은 더 큰 계산을 위한 블록을 생성하기 위해 재귀적으로 중첩될 수 있습니다. 각각의 Layer는 각각의 (학습 가능한것과 학습 불가능한)가중치를 추적할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5HBH-dtYQuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# `build` 메소드와 함께 앞서 정의된\n",
        "# Linear 클래스를 재사용 해봅시다\n",
        "\n",
        "class MLP(Layer):\n",
        "    \"\"\"Linear Layer의 간단한 층을 쌓는 Layer 입니다.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.linear_1 = Linear(32)\n",
        "        self.linear_2 = Linear(32)\n",
        "        self.linear_3 = Linear(10)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.linear_1(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.linear_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        return self.linear_3(x)\n",
        "\n",
        "mlp = MLP()\n",
        "\n",
        "# `mlp` 객체에 대한 첫 번째 호출은 가중치를 생성하게 됩니다.\n",
        "y = mlp(tf.ones(shape=(3, 64)))\n",
        "\n",
        "# 가중치들은 재귀적으로 추적됩니다.\n",
        "assert len(mlp.weights) == 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WavMVtXGQk-z",
        "colab_type": "text"
      },
      "source": [
        "## 미리 정의된 Layer의 종류\n",
        "\n",
        "Keras는 [넓은 범위의 미리 정의된 Layer의 종류](https://www.tensorflow.org/api_docs/python/tf/keras/layers/)를 제공하여 항상 여러분 스스로가 모든것을 구현하지 않아도 되도록끔 해 줍니다.\n",
        "\n",
        "- Convolution layers\n",
        "- Transposed convolutions\n",
        "- Separateable convolutions\n",
        "- Average and max pooling\n",
        "- Global average and max pooling\n",
        "- LSTM, GRU (with built-in cuDNN acceleration)\n",
        "- BatchNormalization\n",
        "- Dropout\n",
        "- Attention\n",
        "- ConvLSTM2D\n",
        "- etc.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdrw7OppQ6At",
        "colab_type": "text"
      },
      "source": [
        "Keras는 디폴트로 좋은 설정값을 노출시키는 원칙을 따릅니다. 이렇게 해서, 필요한 인자값을 디폴트값으로 내버려두어도 대부분의 경우에서 잘 동작할 수 있게끔 해 줍니다. 예를 들어서, `LSTM` Layer는 디폴트로 직교 순환 행렬 초기화자(orthogonal recurrent matrix intializer)를 사용하고, 이는 forget 게이트의 편향값을 1로써 초기화 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oq88tadFz8Z",
        "colab_type": "text"
      },
      "source": [
        "## `call` 메소드의 `training` 인자\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2NkTT0AQV8j",
        "colab_type": "text"
      },
      "source": [
        "몇 Layer, 특히 `BatchNormalization`과 `Dropout` Layer,는 학습과 추론단계에서 서로다른 동작방식을 가집니다. 이러한 종류의 Layer에 대해선, `call` 메소으의 (부울 형식인)`training` 인자를 노출시키는 것이 표준적인 관례입니다.\n",
        "\n",
        "`call` 메소드의 이 인자를 노출시킴으로써, 미리 제공되는 학습과 평가 반복문(예를 들어서 `fit` 메소드)이 해당 Layer를 학습과 추론에 대해서 옳바르게 사용할 수 있게 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysXzHB5KJiLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dropout(Layer):\n",
        "  \n",
        "  def __init__(self, rate):\n",
        "    super(Dropout, self).__init__()\n",
        "    self.rate = rate\n",
        "\n",
        "  def call(self, inputs, training=None):\n",
        "    if training:\n",
        "      return tf.nn.dropout(inputs, rate=self.rate)\n",
        "    return inputs\n",
        "\n",
        "class MLPWithDropout(Layer):\n",
        "\n",
        "  def __init__(self):\n",
        "      super(MLPWithDropout, self).__init__()\n",
        "      self.linear_1 = Linear(32)\n",
        "      self.dropout = Dropout(0.5)\n",
        "      self.linear_3 = Linear(10)\n",
        "\n",
        "  def call(self, inputs, training=None):\n",
        "      x = self.linear_1(inputs)\n",
        "      x = tf.nn.relu(x)\n",
        "      x = self.dropout(x, training=training)\n",
        "      return self.linear_3(x)\n",
        "    \n",
        "mlp = MLPWithDropout()\n",
        "y_train = mlp(tf.ones((2, 2)), training=True)\n",
        "y_test = mlp(tf.ones((2, 2)), training=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyC7KfV-YcYS",
        "colab_type": "text"
      },
      "source": [
        "## 좀 더 함수형적으로 모델을 정의하기 위한 방법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxbEQANKQB6F",
        "colab_type": "text"
      },
      "source": [
        "딥 러닝 모델을 만들기 위해서, 항상 객체지향적 프로그래밍 방법을 사용할 필요는 없습니다. 아래의 예시처럼 Layer들은 함수형적으로도 조합이 가능합니다 (\"함수형 API\" 라고 부릅니다):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiL-0N7sYc6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# `Input` 객체를 사용해서, 입력의 shape(모양)과 dtype(데이터형)을 묘사합니다.\n",
        "# 딥러닝에서 이는 데이터형을 선언하는 방식입니다.\n",
        "# shape 인자는 샘플당 으로, 배치 크기를 포함하지 않습니다. \n",
        "# 함수형 API는 샘플당 변형을 정의하는데 집중합니다.\n",
        "# 생성하는 모델은 자동으로 샘플당 변형에 대한 배치를 고려합니다.\n",
        "# 따라서, 모델은 데이터의 배치마다 호출됩니다.\n",
        "inputs = tf.keras.Input(shape=(16,))\n",
        "\n",
        "# 이러한 \"데이터형\"의 객체에 대해서 Layer를 호출하고,\n",
        "# 호출 결과로 갱신된 (새로운 shape과 dtype을 가지는)\"데이터형\"을 반환합니다.\n",
        "x = Linear(32)(inputs) # 앞서 정의된 Linear Layer를 재사용 합니다.\n",
        "x = Dropout(0.5)(x)    # 앞서 정의된 Droptout Layer를 재사용 합니다.\n",
        "outputs = Linear(10)(x)\n",
        "\n",
        "# 함수형 `모델(Model)`은 입력과 출력을 명시하여 정의될 수 있습니다.\n",
        "# 모델은 다른것과 마찬가지로 스스로가 또 하나의 Layer가 됩니다.\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# 함수형 모델은 호출되기전, 이미 가중치를 가집니다.\n",
        "# 그 이유는 입력에 대한 shape을 `input`에서 사전에 정의했기 때문입니다.\n",
        "assert len(model.weights) == 4\n",
        "\n",
        "# 똑같은 데이터에 대해서, 모델을 다시 호출해 봅시다.\n",
        "y = model(tf.ones((2, 16)))\n",
        "assert y.shape == (2, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK5HqnT3Xgcz",
        "colab_type": "text"
      },
      "source": [
        "함수형 API는 하위 클래스를 만드는것 보다 더 간결하고, 여기엔 몇몇 부가적인 이점(일반적으로 함수형, 형 선언적 언어가 형 선언적이지 않은 객체지향 개발에 비해 가지는 이점과 동일)이 존재합니다. 하지만, 이는 Layer들의 DAGs를 정의하는데에만 사용될 수 있습니다. 재귀적인 네트워크는 `Layer`의 하위 클래스를 통해서 정의되어야 합니다.\n",
        "\n",
        "함수형 모델과 하위 클래스를 통해 정의된 모델의 주요 다른점은 [이곳](https://medium.com/tensorflow/what-are-symbolic-and-imperative-apis-in-tensorflow-2-0-dfccecb01021)에 설명되어 있습니다.\n",
        "\n",
        "[이곳](https://www.tensorflow.org/alpha/guide/keras/functional)을 방문해서, 함수형 API에 대해 좀 더 배워볼 수 있습니다.\n",
        "\n",
        "연구의 작업 흐름에서, 객체지향 모델과 함수형 모델을 섞어쓰는 자신을 종종 발견하게 될지도 모릅니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p0KngmPTScu",
        "colab_type": "text"
      },
      "source": [
        "단일 입력과 출력을 가지는 Layer을 이용해서, 여러 층으로 구성된 모델에 대하여 `Sequential` 클래스를 사용할 수도 있습니다. 이 클래스는 Layer의 목록을 `Model`로 변환해 줍니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNhTY6frTaP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "\n",
        "model = Sequential([Linear(32), Dropout(0.5), Linear(10)])\n",
        "\n",
        "y = model(tf.ones((2, 16)))\n",
        "assert y.shape == (2, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cydf3i_FFXlh",
        "colab_type": "text"
      },
      "source": [
        "## Loss 클래스\n",
        "\n",
        "Keras는 넓은 범위의 미리 정의된 손실함수에 대한 Loss 클래스를 제공합니다. 이는 `BinaryCrossentropy`, `CategoricalCrossentropy`, `KLDivergence`등과 같은 것이 포함되며 다음과 같이 작동합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "019Nm1eWFaUO",
        "colab_type": "code",
        "outputId": "5bdc7523-d55c-4a79-8b65-978970c1cd5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "bce = tf.keras.losses.BinaryCrossentropy()\n",
        "y_true = [0., 0., 1., 1.]  # 목표 (레이블)\n",
        "y_pred = [1., 1., 1., 0.]  # 예측 결과\n",
        "loss = bce(y_true, y_pred)\n",
        "print('손실:', loss.numpy())"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "손실: 11.522857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smbxFMGXY83U",
        "colab_type": "text"
      },
      "source": [
        "Loss 클래스는 상태를 가지지 않습니다. 즉, `__call__`의 출력은 입력에 대한 함수일 뿐입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNLZsnswFbE_",
        "colab_type": "text"
      },
      "source": [
        "## Metric 클래스\n",
        "\n",
        "또한, Keras는 넓은 범위의 미리 정의된 평가지표 함수에 대한 Metric 클래스를 제공합니다. 이는 `BinaryAccuracy`, `AUC`, `FalsePositives`등과 같은것을 포함합니다.\n",
        "\n",
        "Loss와는 다르게, Metric은 상태를 가집니다. `update_state` 메소드를 사용해서 상태를 갱신하고, `result`를 사용해서 스칼라형태의 결과값을 요청할 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dUZkMWATKMC",
        "colab_type": "code",
        "outputId": "c079d62e-96e6-4b80-acf3-53bcfe3332d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "m = tf.keras.metrics.AUC()\n",
        "m.update_state([0, 1, 1, 1], [0, 1, 0, 0])\n",
        "print('중간 결과: ', m.result().numpy())\n",
        "\n",
        "m.update_state([1, 1, 1, 1], [0, 1, 1, 0])\n",
        "print('최종 결과: ', m.result().numpy())"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "중간 결과:  0.6666667\n",
            "최종 결과:  0.71428573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doUSrciie2Px",
        "colab_type": "text"
      },
      "source": [
        "내부 상태는 `metric.reset_states`에 의해 초기화될 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwx7DjFBZ-C-",
        "colab_type": "text"
      },
      "source": [
        "`Metric` 클래스의 하위 클래스를 만들어서, 여러분만의 평가지표 함수를 손쉽게 만들수도 있습니다:\n",
        "\n",
        "- `__init__`내의 상태 변수를 생성합니다\n",
        "- `update_state`내에서 인자로써 주어진 `y_true`와 `y_pred`를 이용해서 변수를 갱신합니다\n",
        "- `result`내에서 평가지표의 결과를 반환합니다\n",
        "- `reset_states`내에서 상태를 초기화 합니다\n",
        "\n",
        "다음은 이 방법을 보여주기 위한 목적으로, `BinaryTruePositive` 평가지표에 대한 구현하고 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVByLrJyaBx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BinaryTruePositives(tf.keras.metrics.Metric):\n",
        "\n",
        "  def __init__(self, name='binary_true_positives', **kwargs):\n",
        "    super(BinaryTruePositives, self).__init__(name=name, **kwargs)\n",
        "    self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
        "\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    y_true = tf.cast(y_true, tf.bool)\n",
        "    y_pred = tf.cast(y_pred, tf.bool)\n",
        "\n",
        "    values = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))\n",
        "    values = tf.cast(values, self.dtype)\n",
        "    if sample_weight is not None:\n",
        "      sample_weight = tf.cast(sample_weight, self.dtype)\n",
        "      sample_weight = tf.broadcast_weights(sample_weight, values)\n",
        "      values = tf.multiply(values, sample_weight)\n",
        "    self.true_positives.assign_add(tf.reduce_sum(values))\n",
        "\n",
        "  def result(self):\n",
        "    return self.true_positives\n",
        "\n",
        "  def reset_states(self):\n",
        "    self.true_positive.assign(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0PdvHdAdQl0",
        "colab_type": "text"
      },
      "source": [
        "## Optimizer 클래스 & 빠른 end-to-end 학습 반복문\n",
        "\n",
        "앞서 보여진 선형회귀 예제에서 작성한, 경사하강시 변수값을 직접 갱신하는 방법은 일반적으로 하지 않아도 됩니다. 보통은 `SGD`, `RMSprop`, 또는 `Adam`등과 같이 Keras에서 미리 제공되는 Optimizer 중 하나를 사용하면 됩니다.\n",
        "\n",
        "아래는 MNIST 데이터에 대해서, Loss, Metric 클래스와 Optimizer가 모두 함께 사용되는 예를 보여줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jNl1ykEdkj8",
        "colab_type": "code",
        "outputId": "8e1c8f12-bbe5-4ce1-dbb4-52763360417d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        }
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "# 데이터셋를 준비합니다\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train[:].reshape(60000, 784).astype('float32') / 255\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(64)\n",
        "\n",
        "# 간단한 분류를 위한 모델의 인스턴스를 만듭니다\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Dense(256, activation=tf.nn.relu),\n",
        "  layers.Dense(256, activation=tf.nn.relu),\n",
        "  layers.Dense(10)\n",
        "])\n",
        "\n",
        "# 정수형 레이블을 인자로 받아들이는, 로지스틱 Loss의 인스턴스를 만듭니다\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# 정확도에 대한 Metric의 인스턴스를 만듭니다\n",
        "accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "# Optimizer의 인스턴스를 만듭니다\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# 데이터셋의 데이터 배치를 순회합니다\n",
        "for step, (x, y) in enumerate(dataset):\n",
        "  \n",
        "  # GradientTape 열어줍니다\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    # 순방향 전파(forward)를 수행합니다\n",
        "    logits = model(x)\n",
        "\n",
        "    # 현재 배치에 대한 손실값을 측정합니다\n",
        "    loss_value = loss(y, logits)\n",
        "     \n",
        "  # 손실에 대한 가중치의 경사도를 계산합니다\n",
        "  gradients = tape.gradient(loss_value, model.trainable_weights)\n",
        "  \n",
        "  # 모델의 가중치를 갱신합니다\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "\n",
        "  # 현재까지 수행된 전체에 대한 모델의 정확도를 갱신합니다\n",
        "  accuracy.update_state(y, logits)\n",
        "  \n",
        "  # 로그를 출력합니다\n",
        "  if step % 100 == 0:\n",
        "    print('단계(Step):', step)\n",
        "    print('마지막 단계(Step)의 손실:', float(loss_value))\n",
        "    print('지금까지 수행된 전체에 대한 정확도:', float(accuracy.result()))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "단계(Step): 0\n",
            "마지막 단계(Step)의 손실: 2.341179132461548\n",
            "지금까지 수행된 전체에 대한 정확도: 0.03125\n",
            "단계(Step): 100\n",
            "마지막 단계(Step)의 손실: 0.33624351024627686\n",
            "지금까지 수행된 전체에 대한 정확도: 0.843440592288971\n",
            "단계(Step): 200\n",
            "마지막 단계(Step)의 손실: 0.18553781509399414\n",
            "지금까지 수행된 전체에 대한 정확도: 0.8798196315765381\n",
            "단계(Step): 300\n",
            "마지막 단계(Step)의 손실: 0.3094934821128845\n",
            "지금까지 수행된 전체에 대한 정확도: 0.8974252343177795\n",
            "단계(Step): 400\n",
            "마지막 단계(Step)의 손실: 0.20692837238311768\n",
            "지금까지 수행된 전체에 대한 정확도: 0.9101075530052185\n",
            "단계(Step): 500\n",
            "마지막 단계(Step)의 손실: 0.23231974244117737\n",
            "지금까지 수행된 전체에 대한 정확도: 0.9177582263946533\n",
            "단계(Step): 600\n",
            "마지막 단계(Step)의 손실: 0.1896420568227768\n",
            "지금까지 수행된 전체에 대한 정확도: 0.9241368770599365\n",
            "단계(Step): 700\n",
            "마지막 단계(Step)의 손실: 0.11397643387317657\n",
            "지금까지 수행된 전체에 대한 정확도: 0.9284726977348328\n",
            "단계(Step): 800\n",
            "마지막 단계(Step)의 손실: 0.22063642740249634\n",
            "지금까지 수행된 전체에 대한 정확도: 0.9317259788513184\n",
            "단계(Step): 900\n",
            "마지막 단계(Step)의 손실: 0.03219543397426605\n",
            "지금까지 수행된 전체에 대한 정확도: 0.9354883432388306\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIJYBrXoekXD",
        "colab_type": "text"
      },
      "source": [
        "`SparseCategoricalAccuracy` Metric 인스턴스를 재사용해서 테스트 반복문을 구현할 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl6FKvqbeqX9",
        "colab_type": "code",
        "outputId": "8cfb7a4d-cdc7-4d70-edc4-094fbae6d44c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_test = x_test[:].reshape(10000, 784).astype('float32') / 255\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_dataset = test_dataset.batch(128)\n",
        "\n",
        "accuracy.reset_states()  # 이 코드는 Metric의 내부 상태를 초기화 합니다\n",
        "\n",
        "for step, (x, y) in enumerate(test_dataset):\n",
        "  logits = model(x)\n",
        "  accuracy.update_state(y, logits)\n",
        "\n",
        "print('최종 테스트 정확도:', float(accuracy.result()))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "최종 테스트 정확도: 0.9593999981880188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEP7jzC8YVWy",
        "colab_type": "text"
      },
      "source": [
        "## `add_loss` 메소드\n",
        "\n",
        "때로는 순방향 전파(forward) 수행 중 손실값을 계산해 보고 싶을 수 있습니다 (특히, 정규화(regularization) 손실에 대해서). Keras는 어느시점에서든지 손실값을 계산할 수 있게 해 주고, `add_loss` 메소드를 통해 이 손실값을 재귀적으로 계속 추적할 수 있게 해 줍니다.\n",
        "\n",
        "다음은 입력에 대한 L2 노름에 기반한 희소 정규화(regularization) 손실을 추가하는 Layer의 예를 보여줍니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbBVP--jYgHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ActivityRegularization(Layer):\n",
        "  \"\"\"활성 희소 정규화 손실(activity sparsity regularization loss)을 생성하는 Layer 입니다\"\"\"\n",
        "  \n",
        "  def __init__(self, rate=1e-2):\n",
        "    super(ActivityRegularization, self).__init__()\n",
        "    self.rate = rate\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    # 입력값에 기반하는\n",
        "    # `add_loss`를 사용해서 정규화 손실을 생성합니다\n",
        "    self.add_loss(self.rate * tf.reduce_sum(tf.square(inputs)))\n",
        "    return inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4qoQk7abK5v",
        "colab_type": "text"
      },
      "source": [
        "`add_loss`를 이용해서 추가된 손실값은 `Layer` 또는 `Model`의 리스트형 속성인 `.losses`를 통해서 접근이 가능합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlJc_4pbbQ2N",
        "colab_type": "code",
        "outputId": "4f487149-5cb9-4ed4-a740-58ad88d15b18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "class SparseMLP(Layer):\n",
        "  \"\"\"희소 정규화 손실을 가지는 선형 계층을 쌓아올린 Layer 입니다\"\"\"\n",
        "\n",
        "  def __init__(self, output_dim):\n",
        "      super(SparseMLP, self).__init__()\n",
        "      self.dense_1 = layers.Dense(32, activation=tf.nn.relu)\n",
        "      self.regularization = ActivityRegularization(1e-2)\n",
        "      self.dense_2 = layers.Dense(output_dim)\n",
        "\n",
        "  def call(self, inputs):\n",
        "      x = self.dense_1(inputs)\n",
        "      x = self.regularization(x)\n",
        "      return self.dense_2(x)\n",
        "    \n",
        "\n",
        "mlp = SparseMLP(1)\n",
        "y = mlp(tf.ones((10, 10)))\n",
        "\n",
        "print(mlp.losses)  # float32 자료형의 단일 스칼라값을 가지는 리스트 입니다"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Tensor: id=186153, shape=(), dtype=float32, numpy=0.79275525>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkI3GA2TbWvY",
        "colab_type": "text"
      },
      "source": [
        "이 손실값들은 순방향 전파(forward)의 시작점에 있는 최상위 Layer로부터 초기화되며 축적되지 않습니다. 따라서 `layer.losses`는 항상 마지막 순방향 전파동안 생성된 손실값만을 가지게 됩니다. 학습 반복문을 작성할 때, 일반적으로 경사도 계산 이전에 이 손실값들에 대한 합산을 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m0xNYGEbZe2",
        "colab_type": "code",
        "outputId": "533fa384-3c07-4f19-815b-a5230e4495c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "# *마지막* 순방향 전파에 해당하는 손실값들 입니다\n",
        "mlp = SparseMLP(1)\n",
        "mlp(tf.ones((10, 10)))\n",
        "assert len(mlp.losses) == 1\n",
        "mlp(tf.ones((10, 10)))\n",
        "assert len(mlp.losses) == 1  # 축적되지 않습니다\n",
        "\n",
        "# 이 손실값들을 학습 반복문에서 사용하는법을 보여줍니다\n",
        "\n",
        "# 데이터셋을 준비합니다\n",
        "(x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train.reshape(60000, 784).astype('float32') / 255, y_train))\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(64)\n",
        "\n",
        "# 새로운 MLP를 만듭니다\n",
        "mlp = SparseMLP(10)\n",
        "\n",
        "# Loss와 Optimizer를 만듭니다\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
        "\n",
        "for step, (x, y) in enumerate(dataset):\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    # 순방향 전파를 수행합니다\n",
        "    logits = mlp(x)\n",
        "\n",
        "    # 현재 배치에 대한 외부의 손실값을 계산합니다\n",
        "    loss = loss_fn(y, logits)\n",
        "    \n",
        "    # 순방향 전파시 생성된 손실값을 더해줍니다 \n",
        "    loss += sum(mlp.losses)\n",
        "     \n",
        "    # 해당 손실에 대한 가중치의 경사도를 계산합니다\n",
        "    gradients = tape.gradient(loss, mlp.trainable_weights)\n",
        "  \n",
        "  # 모델의 가중치를 갱신합니다\n",
        "  optimizer.apply_gradients(zip(gradients, mlp.trainable_weights))\n",
        "  \n",
        "  # 로그를 출력합니다\n",
        "  if step % 100 == 0:\n",
        "    print(step, float(loss))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 4.2266459465026855\n",
            "100 2.2934560775756836\n",
            "200 2.2962656021118164\n",
            "300 2.1863455772399902\n",
            "400 2.158012866973877\n",
            "500 2.1282315254211426\n",
            "600 2.0247669219970703\n",
            "700 2.041032314300537\n",
            "800 1.9458585977554321\n",
            "900 1.7418930530548096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zecO65f2Ph7O",
        "colab_type": "text"
      },
      "source": [
        "## 자세한 end-to-end 예제: Variational AutoEncoder (VAE)\n",
        "\n",
        "기초적인 내용의 공부를 잠시 미뤄두고, 약간 더 어려운 예제를 살펴보고 싶다면, [여기에 소개된 VAE](https://www.tensorflow.org/guide/keras/custom_layers_and_models#putting_it_all_together_an_end-to-end_example)에 대한 구현의 예제를 확인해 보시기 바랍니다. 이는 여러분이 지금까지 배워왔던 모든것의 내용을 담고 있습니다:\n",
        "\n",
        "- `Layer`의 하위 클래스를 만드는것\n",
        "- 재귀적으로 Layer를 구성하는것\n",
        "- Loss 및 Metric 클래스에 대한것\n",
        "- `add_loss`\n",
        "- `GradientTape`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V0yRrfYFuVT",
        "colab_type": "text"
      },
      "source": [
        "## 미리 정의된 학습 반복문을 사용하는것"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNwAjgEXPpnP",
        "colab_type": "text"
      },
      "source": [
        "간단한 케이스에 대해서 조차 여러분이 스스로 저수준의 학습 반복문을 매번 작성해야 한다면, 이는 어리석은 일일지도 모릅니다. Keras는 미리 정의된 학습 반복문을 `Model` 클래스에서 제공합니다. 사용하고자 한다면, `Model`의 하위 클래스를 만들거나 `Functional(함수형)` 또는 `Sequential(순차형)` 모델을 생성하면 됩니다.\n",
        "\n",
        "이를 보여주기 위해서, 앞서 만들어둔 MNIST의 예를 재사용 해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omdNf2x4jovv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터셋을 준비합니다\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(64)\n",
        "\n",
        "# 간단한 분류모델의 인스턴스를 만듭니다\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Dense(256, activation=tf.nn.relu),\n",
        "  layers.Dense(256, activation=tf.nn.relu),\n",
        "  layers.Dense(10)\n",
        "])\n",
        "\n",
        "# 정수형 레이블을 인자로 받아들이는, 로지스틱 Loss의 인스턴스를 만듭니다\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# 정확도에 대한 Metric의 인스턴스를 만듭니다\n",
        "accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "# Optimizer의 인스턴스를 만듭니다\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYU5PkaLiriO",
        "colab_type": "text"
      },
      "source": [
        "가장 첫 번째로, `compile` 메소드를 호출하여 Optimizer, Loss, 모니터링하기 위한 Metric을 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo6GhvzjJjdb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=optimizer, loss=loss, metrics=[accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98zDjMPej06U",
        "colab_type": "text"
      },
      "source": [
        "그리고 나선 `fit` 메소드를 호출하고, 이 때 데이터를 전달해 줍니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OdztL4nj4ed",
        "colab_type": "code",
        "outputId": "60775952-3d1e-4307-ec71-83a96f4cb4c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "model.fit(dataset, epochs=3)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.2177 - sparse_categorical_accuracy: 0.9361\n",
            "Epoch 2/3\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0842 - sparse_categorical_accuracy: 0.9747\n",
            "Epoch 3/3\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0564 - sparse_categorical_accuracy: 0.9821\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff0b1254fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZc2ss8qln1p",
        "colab_type": "text"
      },
      "source": [
        "이게 끝입니다! 이제는 테스트를 해 봅시다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0-XQbxOlqB3",
        "colab_type": "code",
        "outputId": "48fba149-48b6-44c2-87f2-5126edbcc8dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "x_test = x_test[:].reshape(10000, 784).astype('float32') / 255\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_dataset = test_dataset.batch(128)\n",
        "\n",
        "loss, acc = model.evaluate(test_dataset)\n",
        "print('손실:', loss, '정확도:', acc)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0949 - sparse_categorical_accuracy: 0.9712\n",
            "손실: 0.09488680568940737 정확도: 0.9712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkmbEn55nV7y",
        "colab_type": "text"
      },
      "source": [
        "`fit`이 수행되는 동안 검증용 데이터셋에 대한 Loss와 Metric을 모니터링 하는것 또한 가능합니다.\n",
        "\n",
        "또한, Numpy형의 배열에 대해서도 직접적으로 `fit`을 호출할 수 있습니다. 따라서 데이터셋에 대한 변환이 필요 없습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q8UuNivngVe",
        "colab_type": "code",
        "outputId": "b074da4c-dcd2-4dd1-cc32-2beeab0ded3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
        "\n",
        "num_val_samples = 10000\n",
        "x_val = x_train[-num_val_samples:]\n",
        "y_val = y_train[-num_val_samples:]\n",
        "x_train = x_train[:-num_val_samples]\n",
        "y_train = y_train[:-num_val_samples]\n",
        "\n",
        "# 간단한 분류모델의 인스턴스를 만듭니다\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Dense(256, activation=tf.nn.relu),\n",
        "  layers.Dense(256, activation=tf.nn.relu),\n",
        "  layers.Dense(10)\n",
        "])\n",
        "\n",
        "# 정수형 레이블을 인자로 받아들이는, 로지스틱 Loss의 인스턴스를 만듭니다\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# 정확도에 대한 Metric의 인스턴스를 만듭니다\n",
        "accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "# Optimizer의 인스턴스를 만듭니다\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss,\n",
        "              metrics=[accuracy])\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          epochs=3,\n",
        "          batch_size=64)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "50000/50000 [==============================] - 4s 83us/sample - loss: 0.2399 - sparse_categorical_accuracy: 0.9292 - val_loss: 0.1223 - val_sparse_categorical_accuracy: 0.9632\n",
            "Epoch 2/3\n",
            "50000/50000 [==============================] - 4s 75us/sample - loss: 0.0951 - sparse_categorical_accuracy: 0.9704 - val_loss: 0.0872 - val_sparse_categorical_accuracy: 0.9747\n",
            "Epoch 3/3\n",
            "50000/50000 [==============================] - 4s 73us/sample - loss: 0.0616 - sparse_categorical_accuracy: 0.9805 - val_loss: 0.0805 - val_sparse_categorical_accuracy: 0.9755\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff0afa09278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88ExjKfCo7aP",
        "colab_type": "text"
      },
      "source": [
        "## Callbacks\n",
        "\n",
        "`fit`이 가지는 간단하지만 훌륭한 기능 중 하나로, [callbacks](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/)을 사용해서 학습과 평가 도중 일어나는 일에 대한 사용자 정의화가 가능합니다.\n",
        "\n",
        "Callback은 객체의 한 종류로, 학습 중간 중간에 호출(예를들어, 매 배치마다 또는 매 epoch마다) 되며 어떤 작업을 수행합니다.\n",
        "\n",
        "미리 정의된 여러가지 Callback이 존재합니다. `ModelCheckpoint`는 학습도중 매 epoch마다 모델을 저장하고, `EarlyStopping`은 검증용 평가지표(metrics)가 향상되지 않을 때 학습을 중단시킵니다.\n",
        "\n",
        "물론, 손쉽게 [여러분만의 callback을 작성할 수도 있습니다](https://www.tensorflow.org/guide/keras/custom_callback).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAylVdYJqcZ3",
        "colab_type": "code",
        "outputId": "c870e05a-acb6-4da3-db83-1a8f4805734d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "# 간단한 분류모델의 인스턴스를 만듭니다\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Dense(256, activation=tf.nn.relu),\n",
        "  layers.Dense(256, activation=tf.nn.relu),\n",
        "  layers.Dense(10)\n",
        "])\n",
        "\n",
        "# 정수형 레이블을 인자로 받아들이는, 로지스틱 Loss의 인스턴스를 만듭니다\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# 정확도에 대한 Metric의 인스턴스를 만듭니다\n",
        "accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "# Optimizer의 인스턴스를 만듭니다\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss,\n",
        "              metrics=[accuracy])\n",
        "\n",
        "# 몇가지 Callback의 인스턴스를 만듭니다\n",
        "callbacks = [tf.keras.callbacks.EarlyStopping(),\n",
        "             tf.keras.callbacks.ModelCheckpoint(filepath='my_model.keras',\n",
        "                                                save_best_only=True)]\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          epochs=30,\n",
        "          batch_size=64,\n",
        "          callbacks=callbacks)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 4s 83us/sample - loss: 0.2432 - sparse_categorical_accuracy: 0.9281 - val_loss: 0.1253 - val_sparse_categorical_accuracy: 0.9635\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 4s 72us/sample - loss: 0.0939 - sparse_categorical_accuracy: 0.9717 - val_loss: 0.0964 - val_sparse_categorical_accuracy: 0.9695\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 4s 72us/sample - loss: 0.0635 - sparse_categorical_accuracy: 0.9800 - val_loss: 0.0788 - val_sparse_categorical_accuracy: 0.9774\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 4s 70us/sample - loss: 0.0456 - sparse_categorical_accuracy: 0.9858 - val_loss: 0.0845 - val_sparse_categorical_accuracy: 0.9757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff0af546748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxINLLGitX_n",
        "colab_type": "text"
      },
      "source": [
        "# 작별 인사\n",
        "\n",
        "저는 이 가이드가 여러분에게 TensorFlow2.0과 Keras로 무엇을 할 수 있는지 알려주는 좋은 오버뷰가 되길 희망합니다!\n",
        "\n",
        "TensorFlow와 Keras는 단일 작업 흐름만을 대변하는게 아니라는 것을 기억하세요. 사용성과 유연성이라는 트레이드오프를 가지는 여러 범위의 작업흐름을 지원합니다. 예를 들어서, `fit` 메소드를 사용하는것이 사용자정의 학습 반복문을 작성하는것보다 훨씬 쉽지만, `fit`은 연구에서 필요한 미세한 조절이 가능한 수준까지를 제공하진 못합니다.\n",
        "\n",
        "따라서, 여러분의 일에 맞는 알맞은 툴을 사용하세요!\n",
        "\n",
        "Keras의 중심이 되는 원칙은 \"복잡도의 점진적인 공개\" 입니다. 매우 쉽게 시작할 수 있고, 점점 더 많은 부분을 밑바닥에서 부터 구현해야 하는 작업흐름에 대해서 점진적으로 좀 더 깊이 들여다보고, 그렇게함으로써 완전한 제어를 할 수 있게 됩니다.\n",
        "\n",
        "\n",
        "이 사실은 모델의 정의와 모델의 학습 모두에 적용되는 것입니다.\n",
        "\n",
        "![모델의 정의: 작업 흐름의 범위](https://drive.google.com/uc?export=view&id=1bTHrw-OXaKqnJI-DVGG04suWHVOl8UVj)\n",
        "\n",
        "![모델의 학습: 작업 흐름의 범위](https://drive.google.com/uc?export=view&id=1a6oMJ9IKyMg19JX7NkihyOfzdiJo5Mpq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfO_uy61upRm",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## 이 다음으로 보면 좋을만한 것들\n",
        "\n",
        "이 가이드 다음으로, 여러분이 관심을 가질만한 주제가 더 있습니다:\n",
        "\n",
        "- [저장과 직렬화](https://www.tensorflow.org/guide/keras/save_and_serialize)\n",
        "- [다중 GPUs에서의 분산 학습](https://www.tensorflow.org/guide/distributed_training)\n",
        "- [임베디드 시스템이나 안드로이드 개발에 활용하기 위해 모델을 TFLite로 내보내기](https://www.tensorflow.org/lite/convert/python_api#converting_a_keras_model_)\n",
        "- [브라우져에서의 개발에 활용하기 위해 모델을 TensorFlow.js로 내보내기](https://www.tensorflow.org/js/tutorials/conversion/import_keras)"
      ]
    }
  ]
}